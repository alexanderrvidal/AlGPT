{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tiktoken as tk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tiktoken  # Ensure tiktoken is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset 1115394\n"
     ]
    }
   ],
   "source": [
    "with open ('data.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "\n",
    "print('length of dataset', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "vocab size 65\n"
     ]
    }
   ],
   "source": [
    "# extract the unique characters that occur in this text \n",
    "chars = sorted(list(set(data)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print('vocab size', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [46, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42]\n",
      "decoded: hello world\n"
     ]
    }
   ],
   "source": [
    "# develope a strategy to tokenize the input text \n",
    "# create a mapping from characters to integers\n",
    "char_to_int = {ch:i for i,ch in enumerate(chars)} # create a dictionary that maps characters to integers\n",
    "int_to_char = {i:ch for i,ch in enumerate(chars)} # create a dictionary that maps integers to characters\n",
    "encode = lambda x: [char_to_int[ch] for ch in x] # take a string and convert it to a list of integers\n",
    "decode = lambda x: ''.join([int_to_char[ch] for ch in x]) # take the list of integers and convert it back to a string\n",
    "\n",
    "print('encoded:', encode('hello world'))\n",
    "print('decoded:', decode(encode('hello world')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31373, 995]\n",
      "hello world\n",
      "number of classes: 50257\n"
     ]
    }
   ],
   "source": [
    "# Using tiktoken instead of the above simple tokenizer\n",
    "enc = tk.get_encoding('gpt2')\n",
    "print(enc.encode('hello world'))\n",
    "print(enc.decode(enc.encode('hello world')))\n",
    "\n",
    "# get number of classes from the tokenizer for the data.txt file \n",
    "print('number of classes:', enc.n_vocab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LLModel(nn.Module):\n",
    "    def __init__(self, block_size=128, batch_size=32, lr=5e-3):\n",
    "        \"\"\"\n",
    "        Initializes the LLModel class with a transformer model.\n",
    "        \"\"\"\n",
    "        super().__init__()  # Ensure the nn.Module is properly initialized\n",
    "\n",
    "        # Device setup\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "        # Tokenizer setup using tiktoken\n",
    "        self.tokenizer = tiktoken.get_encoding('gpt2')\n",
    "        self.token_encoder = self.tokenizer.encode\n",
    "        self.token_decoder = self.tokenizer.decode\n",
    "        self.vocab_size = self.tokenizer.n_vocab\n",
    "        self.num_classes = self.vocab_size  # Assuming token-level classification\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.block_size = block_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Transformer model\n",
    "        self.model = TransformerModel(\n",
    "            vocab_size=self.vocab_size,\n",
    "            embed_dim=128,\n",
    "            num_heads=8,\n",
    "            hidden_dim=256,\n",
    "            num_layers=2,\n",
    "            num_classes=self.num_classes\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Loss function & optimizer\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.AdamW(self.model.parameters(), lr=lr)\n",
    "\n",
    "    def get_batch(self, tokenized_data, split='train'):\n",
    "        \"\"\"\n",
    "        Generates a batch of input sequences based on tokenized data\n",
    "        \"\"\"\n",
    "        # Ensure enough data points are available\n",
    "        if len(tokenized_data) <= self.block_size:\n",
    "            raise ValueError(\"Not enough data for the given block size.\")\n",
    "\n",
    "        # Select train or validation set\n",
    "        data = tokenized_data if split == 'train' else tokenized_data  # Adjust if needed\n",
    "\n",
    "        ix = torch.randint(len(data) - self.block_size, (self.batch_size,))\n",
    "        x = torch.stack([data[i : i + self.block_size] for i in ix])  # Shape: (batch_size, block_size)\n",
    "        y = torch.stack([data[i + 1 : i + self.block_size + 1] for i in ix])  # Shape: (batch_size, block_size)\n",
    "        assert x.shape == y.shape, \"Input and target shapes do not match.\"\n",
    "        assert x.shape == (self.batch_size, self.block_size), f\"Invalid batch shape: {x.shape}\"\n",
    "        assert y.shape == (self.batch_size, self.block_size), f\"Invalid target shape: {y.shape}\"\n",
    "        return x, y\n",
    "\n",
    "    def train_model(self, text_data, epochs=1000, print_freq=10, train_val_split=0.9):\n",
    "        \"\"\"\n",
    "        Trains the model on input text data.\n",
    "        \"\"\"\n",
    "        best_loss = float('inf')\n",
    "        tokenized_data = torch.tensor(self.token_encoder(text_data), dtype=torch.long, device=self.device)\n",
    "        n = int(train_val_split * len(tokenized_data))\n",
    "        train_data, val_data = tokenized_data[:n], tokenized_data[n:]\n",
    "        print('train data:', train_data.shape, 'val data:', val_data.shape)\n",
    "        x, y = self.get_batch(train_data, 'train')\n",
    "        x_val, y_val = self.get_batch(val_data, 'train')\n",
    "        # load the best model if it exists\n",
    "        try:\n",
    "            self.model.load_state_dict(torch.load('best_model.pth'))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            logits = self.model(x)\n",
    "            loss = self.criterion(logits.view(-1, self.num_classes), y.view(-1))\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            val_loss = self.criterion(self.model(x_val).view(-1, self.num_classes), y_val.view(-1))\n",
    "\n",
    "            # Save the best model\n",
    "            if loss.item() < best_loss:\n",
    "                best_loss = loss.item()\n",
    "                torch.save(self.model.state_dict(), 'best_model.pth')\n",
    "\n",
    "            if epoch % print_freq == 0:\n",
    "                print(f\"Epoch {epoch} | Loss: {loss.item():.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        return best_loss\n",
    "\n",
    "    def evaluate(self, text_data):\n",
    "        \"\"\"\n",
    "        Evaluates the model on a validation batch.\n",
    "        \"\"\"\n",
    "        tokenized_data = torch.tensor(self.token_encoder(text_data), dtype=torch.long, device=self.device)\n",
    "        x, y = self.get_batch(tokenized_data, 'train')\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(x)\n",
    "            loss = self.criterion(logits.view(-1, self.num_classes),y.view(-1))\n",
    "        return loss.item()\n",
    "\n",
    "    def predict(self, text):\n",
    "        tokenized_data = torch.tensor(self.token_encoder(text), device=self.device).unsqueeze(0)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(tokenized_data)\n",
    "            predicted_tokens = torch.argmax(logits, dim=-1)\n",
    "            return self.token_decoder(predicted_tokens.squeeze().tolist())\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embed_dim=128, num_heads=8, hidden_dim=256, num_layers=2, num_classes=50257, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim)\n",
    "        \n",
    "        # Transformer encoder layers with dropout\n",
    "        self.encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, \n",
    "            nhead=num_heads, \n",
    "            dim_feedforward=hidden_dim, \n",
    "            batch_first=True,\n",
    "            dropout=dropout_rate  # Dropout within encoder layers\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            self.encoder_layers, \n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        # Additional dropout before final classification\n",
    "        self.dropout = nn.Dropout(dropout_rate)  \n",
    "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        x = self.embedding(input_ids)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.dropout(x)  # Apply dropout before classification\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements positional encoding for Transformer models.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-torch.log(torch.tensor(10000.0)) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, : x.size(1), :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: torch.Size([304222]) val data: torch.Size([33803])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p0/tgmzcxhd3rs5pm3mkbt2mrxh0000gn/T/ipykernel_7519/1183696306.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 6.3216 | Val Loss: 7.0176\n",
      "Epoch 10 | Loss: 4.5817 | Val Loss: 6.6556\n",
      "Epoch 20 | Loss: 3.2437 | Val Loss: 6.9647\n",
      "Epoch 30 | Loss: 2.2045 | Val Loss: 7.4815\n",
      "Epoch 40 | Loss: 1.4921 | Val Loss: 8.0532\n",
      "Epoch 50 | Loss: 0.9871 | Val Loss: 8.6126\n",
      "Epoch 60 | Loss: 0.6677 | Val Loss: 9.0538\n",
      "Epoch 70 | Loss: 0.4863 | Val Loss: 9.5609\n",
      "Epoch 80 | Loss: 0.3533 | Val Loss: 9.9441\n",
      "Epoch 90 | Loss: 0.2767 | Val Loss: 10.2170\n",
      "Epoch 100 | Loss: 0.2247 | Val Loss: 10.5450\n",
      "Epoch 110 | Loss: 0.1802 | Val Loss: 10.7239\n",
      "Epoch 120 | Loss: 0.1578 | Val Loss: 10.9314\n",
      "Epoch 130 | Loss: 0.1301 | Val Loss: 11.0630\n",
      "Epoch 140 | Loss: 0.1383 | Val Loss: 11.2863\n",
      "Epoch 150 | Loss: 0.1213 | Val Loss: 11.3747\n",
      "Epoch 160 | Loss: 0.0960 | Val Loss: 11.5857\n",
      "Epoch 170 | Loss: 0.0866 | Val Loss: 11.6223\n",
      "Epoch 180 | Loss: 0.0929 | Val Loss: 11.7649\n",
      "Epoch 190 | Loss: 0.0816 | Val Loss: 11.8797\n",
      "Epoch 200 | Loss: 0.0765 | Val Loss: 12.0218\n",
      "Epoch 210 | Loss: 0.0642 | Val Loss: 11.9811\n",
      "Epoch 220 | Loss: 0.0568 | Val Loss: 12.1419\n",
      "Epoch 230 | Loss: 0.0617 | Val Loss: 12.2537\n",
      "Epoch 240 | Loss: 0.0594 | Val Loss: 12.2357\n",
      "Epoch 250 | Loss: 0.0663 | Val Loss: 12.4049\n",
      "Epoch 260 | Loss: 0.0503 | Val Loss: 12.4737\n",
      "Epoch 270 | Loss: 0.0490 | Val Loss: 12.4319\n",
      "Epoch 280 | Loss: 0.0432 | Val Loss: 12.6040\n",
      "Epoch 290 | Loss: 0.0436 | Val Loss: 12.6671\n",
      "Epoch 300 | Loss: 0.0442 | Val Loss: 12.7076\n",
      "Epoch 310 | Loss: 0.0394 | Val Loss: 12.8611\n",
      "Epoch 320 | Loss: 0.0362 | Val Loss: 12.8298\n",
      "Epoch 330 | Loss: 0.0351 | Val Loss: 13.0014\n",
      "Epoch 340 | Loss: 0.0335 | Val Loss: 12.8775\n",
      "Epoch 350 | Loss: 0.0302 | Val Loss: 12.8938\n",
      "Epoch 360 | Loss: 0.0304 | Val Loss: 12.9959\n",
      "Epoch 370 | Loss: 0.0306 | Val Loss: 13.1139\n",
      "Epoch 380 | Loss: 0.0266 | Val Loss: 13.1382\n",
      "Epoch 390 | Loss: 0.0343 | Val Loss: 13.1648\n",
      "Epoch 400 | Loss: 0.0260 | Val Loss: 13.2759\n",
      "Epoch 410 | Loss: 0.0301 | Val Loss: 13.3308\n",
      "Epoch 420 | Loss: 0.0278 | Val Loss: 13.3026\n",
      "Epoch 430 | Loss: 0.0238 | Val Loss: 13.3304\n",
      "Epoch 440 | Loss: 0.0274 | Val Loss: 13.4142\n",
      "Epoch 450 | Loss: 0.0332 | Val Loss: 13.5647\n",
      "Epoch 460 | Loss: 0.0306 | Val Loss: 13.4467\n",
      "Epoch 470 | Loss: 0.0263 | Val Loss: 13.5325\n",
      "Epoch 480 | Loss: 0.0293 | Val Loss: 13.4166\n",
      "Epoch 490 | Loss: 0.0273 | Val Loss: 13.7071\n",
      "Epoch 500 | Loss: 0.0307 | Val Loss: 13.5810\n",
      "Epoch 510 | Loss: 0.0237 | Val Loss: 13.6157\n",
      "Epoch 520 | Loss: 0.0277 | Val Loss: 13.6312\n",
      "Epoch 530 | Loss: 0.0295 | Val Loss: 13.6695\n",
      "Epoch 540 | Loss: 0.0210 | Val Loss: 13.7992\n",
      "Epoch 550 | Loss: 0.0260 | Val Loss: 13.7895\n",
      "Epoch 560 | Loss: 0.0195 | Val Loss: 13.7421\n",
      "Epoch 570 | Loss: 0.0186 | Val Loss: 13.9463\n",
      "Epoch 580 | Loss: 0.0205 | Val Loss: 14.1125\n",
      "Epoch 590 | Loss: 0.0210 | Val Loss: 13.9151\n",
      "Epoch 600 | Loss: 0.0271 | Val Loss: 14.0867\n",
      "Epoch 610 | Loss: 0.0224 | Val Loss: 13.9909\n",
      "Epoch 620 | Loss: 0.0175 | Val Loss: 14.0914\n",
      "Epoch 630 | Loss: 0.0206 | Val Loss: 14.1148\n",
      "Epoch 640 | Loss: 0.0193 | Val Loss: 14.1528\n",
      "Epoch 650 | Loss: 0.0187 | Val Loss: 14.0544\n",
      "Epoch 660 | Loss: 0.0208 | Val Loss: 14.2676\n",
      "Epoch 670 | Loss: 0.0184 | Val Loss: 14.3434\n",
      "Epoch 680 | Loss: 0.0212 | Val Loss: 14.2044\n",
      "Epoch 690 | Loss: 0.0184 | Val Loss: 14.1786\n",
      "Epoch 700 | Loss: 0.0163 | Val Loss: 14.4219\n",
      "Epoch 710 | Loss: 0.0183 | Val Loss: 14.3741\n",
      "Epoch 720 | Loss: 0.0214 | Val Loss: 14.2682\n",
      "Epoch 730 | Loss: 0.0179 | Val Loss: 14.4078\n",
      "Epoch 740 | Loss: 0.0190 | Val Loss: 14.4613\n",
      "Epoch 750 | Loss: 0.0202 | Val Loss: 14.3651\n",
      "Epoch 760 | Loss: 0.0178 | Val Loss: 14.5245\n",
      "Epoch 770 | Loss: 0.0205 | Val Loss: 14.5433\n",
      "Epoch 780 | Loss: 0.0230 | Val Loss: 14.6068\n",
      "Epoch 790 | Loss: 0.0232 | Val Loss: 14.6760\n",
      "Epoch 800 | Loss: 0.0189 | Val Loss: 14.7521\n",
      "Epoch 810 | Loss: 0.0230 | Val Loss: 14.7123\n",
      "Epoch 820 | Loss: 0.0210 | Val Loss: 14.7357\n",
      "Epoch 830 | Loss: 0.0235 | Val Loss: 14.6235\n",
      "Epoch 840 | Loss: 0.0216 | Val Loss: 14.7919\n",
      "Epoch 850 | Loss: 0.0218 | Val Loss: 14.6902\n",
      "Epoch 860 | Loss: 0.0204 | Val Loss: 14.7279\n",
      "Epoch 870 | Loss: 0.0178 | Val Loss: 14.7008\n",
      "Epoch 880 | Loss: 0.0170 | Val Loss: 14.8035\n",
      "Epoch 890 | Loss: 0.0186 | Val Loss: 14.9678\n",
      "Epoch 900 | Loss: 0.0141 | Val Loss: 14.9267\n",
      "Epoch 910 | Loss: 0.0214 | Val Loss: 14.9369\n",
      "Epoch 920 | Loss: 0.0197 | Val Loss: 14.8553\n",
      "Epoch 930 | Loss: 0.0167 | Val Loss: 14.9511\n",
      "Epoch 940 | Loss: 0.0214 | Val Loss: 15.0365\n",
      "Epoch 950 | Loss: 0.0289 | Val Loss: 14.8852\n",
      "Epoch 960 | Loss: 0.0231 | Val Loss: 15.0583\n",
      "Epoch 970 | Loss: 0.0227 | Val Loss: 15.0713\n",
      "Epoch 980 | Loss: 0.0151 | Val Loss: 15.1654\n",
      "Epoch 990 | Loss: 0.0147 | Val Loss: 15.2168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.597416400909424"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = LLModel()\n",
    "model.train_model(data, epochs=1000, print_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' with the? frank banks;g with?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"Jealousy is the green-eyed monster\"\n",
    "model.predict(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
